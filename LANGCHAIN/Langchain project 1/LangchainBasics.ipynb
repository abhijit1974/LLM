{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b973dc17",
   "metadata": {},
   "source": [
    "## LANGCHAIN\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "Get setup with LAngChain, LangSmith and LangServe\n",
    "Use the most basic and common components of LangChain prompt templates and models and output\n",
    "Build a sample application with LangChain\n",
    "Trace application with LangSmith\n",
    "Serve application to production with LangServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8812403f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9fd80d8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LANGCHAIN_PROJECT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLANGCHAIN_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLANGCHAIN_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLANGCHAIN_TRACING_V2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[43mLANGCHAIN_PROJECT\u001b[49m]\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLANGCHAIN_PROJECT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LANGCHAIN_PROJECT' is not defined"
     ]
    }
   ],
   "source": [
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[LANGCHAIN_PROJECT]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8fe13fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000021A7CD40730> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000021A7CDA0C40> root_client=<openai.OpenAI object at 0x0000021A7CCCEA10> root_async_client=<openai.AsyncOpenAI object at 0x0000021A7CD408B0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1fb2209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 14, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_432e014d75', 'id': 'chatcmpl-BKKgb5IDFxRI7yA9nAV7LAumXEEhq', 'finish_reason': 'stop', 'logprobs': None}, id='run-c052a7fd-1334-4c7b-ae80-2323f996c3c5-0', usage_metadata={'input_tokens': 14, 'output_tokens': 8, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input and get response from LLM\n",
    "llm.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "81a98070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Virat Kohli, an Indian cricketer, is widely regarded as one of the best batsmen in the world. As of my last update, here are some general statistics about his career:\\n\\n### Test Cricket\\n- **Matches:** Over 100\\n- **Runs:** Over 8,000\\n- **Average:** Above 50\\n- **Centuries:** 28\\n\\n### One Day Internationals (ODIs)\\n- **Matches:** Over 250\\n- **Runs:** Over 12,000\\n- **Average:** Above 50\\n- **Centuries:** 43\\n\\n### Twenty20 Internationals (T20Is)\\n- **Matches:** Over 100\\n- **Runs:** Over 4,000\\n- **Average:** Around 50\\n\\n### Indian Premier League (IPL)\\n- **Matches:** Over 200\\n- **Runs:** Over 6,000\\n- **Average:** Around 38\\n- **Centuries:** 5\\n\\nPlease note these statistics can change as Kohli continues to play and more matches are recorded. For the most up-to-date statistics, consider checking the latest cricket databases or cricket-related websites.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 238, 'prompt_tokens': 14, 'total_tokens': 252, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'id': 'chatcmpl-BKKhNoqtT7F5Ung5jhxBx53pg0yfc', 'finish_reason': 'stop', 'logprobs': None} id='run-15067ac9-086e-48e5-abde-c62f91c66033-0' usage_metadata={'input_tokens': 14, 'output_tokens': 238, 'total_tokens': 252, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"stats of virat kohli?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe97c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "888a00af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ChatPrompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"You are an expert AI Engineer. Provide answer based on the question\"),\n",
    "     (\"user\", \"{input}\")],\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f71bf298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a sophisticated tool designed for developers working with large language models (LLMs), offering a suite of features to ease the development and optimization process of AI applications. It supports the testing, evaluation, and continuous improvement of LLM-powered applications through several key functionalities:\\n\\n1. **Instrumentation and Monitoring**: Langsmith provides detailed metrics and tracing capabilities, enabling developers to visually track the flow and performance of their language model operations. This is crucial for understanding how the model is interacting within an application context and for identifying bottlenecks or inefficiencies.\\n\\n2. **Evaluation Framework**: It offers tools to evaluate the performance of language models in a systematic way. Developers can set benchmarks and conduct rigorous, repeatable tests to measure the quality and accuracy of their models, helping to ensure the reliability of AI decisions and responses.\\n\\n3. **Data Management**: Langsmith also focuses on the management of datasets, which are integral to training and refining LLMs. It allows for efficient organization, versioning, and tracking of datasets, providing a robust environment to iterate over data changes and measure their impact on model performance.\\n\\n4. **LangChain Integration**: As part of the broader LangChain ecosystem, Langsmith is designed to work seamlessly with this framework, which facilitates the building of applications using LLMs. LangChain provides utilities for the efficient chaining of language model operations, and Langsmith complements this by enhancing observability and control over those processes.\\n\\n5. **Optimization Tools**: With Langsmith, developers receive insights and tools specifically aimed at optimizing LLM usage, such as handling prompt engineering, fine-tuning models, or implementing more efficient run-time operations.\\n\\nOverall, Langsmith aims to make the process of deploying and maintaining language model applications more transparent and manageable, providing a central hub for analyzing and enhancing AI functionality.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 366, 'prompt_tokens': 32, 'total_tokens': 398, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_726d488742', 'id': 'chatcmpl-BK33jfTk1oDnArsmOvB1QPAuyWcUE', 'finish_reason': 'stop', 'logprobs': None} id='run-9c3984e6-a075-4c59-a768-759e42051c21-0' usage_metadata={'input_tokens': 32, 'output_tokens': 366, 'total_tokens': 398, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "### Chain ##\n",
    "\n",
    "chain=prompt|llm\n",
    "response=chain.invoke({\"input\":\"Can you tell me about langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc8e78ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a04a7e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a platform provided by LangChain designed to facilitate the development, debugging, and monitoring of applications that leverage large language models (LLMs). It provides developers with tools and services to effectively manage and optimize their applications that utilize these advanced AI models. Langsmith further enhances the LangChain framework by offering capabilities for observability, enabling developers to track and analyze the performance and behavior of the language models in real-world applications. This is crucial for ensuring quality, reliability, and improvement in applications driven by LLMs.\n"
     ]
    }
   ],
   "source": [
    "## String output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"What are the two usage limits of \""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
